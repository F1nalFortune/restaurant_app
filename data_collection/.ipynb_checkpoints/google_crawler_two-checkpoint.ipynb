{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "from functools import wraps\n",
    "from colorama import Fore\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotVisibleException\n",
    "\n",
    "from requests import ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(ExceptionToCheck, tries=20, delay=3, backoff=2, logger=None):\n",
    "    \"\"\"Retry calling the decorated function using an exponential backoff.\n",
    "\n",
    "    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n",
    "    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n",
    "    \n",
    "    :param ExceptionToCheck: the exception to check. may be a tuple of\n",
    "        exceptions to check\n",
    "    :type ExceptionToCheck: Exception or tuple\n",
    "    :param tries: number of times to try (not retry) before giving up\n",
    "    :type tries: int\n",
    "    :param delay: initial delay between retries in seconds\n",
    "    :type delay: int\n",
    "    :param backoff: backoff multiplier e.g. value of 2 will double the delay\n",
    "        each retry\n",
    "    :type backoff: int\n",
    "    :param logger: logger to use. If None, print\n",
    "    :type logger: logging.Logger instance\n",
    "    \"\"\"\n",
    "    def deco_retry(f):\n",
    "\n",
    "        @wraps(f)\n",
    "        def f_retry(*args, **kwargs):\n",
    "            mtries, mdelay = tries, delay\n",
    "            while mtries > 1:\n",
    "                try:\n",
    "                    return f(*args, **kwargs)\n",
    "                except ExceptionToCheck:\n",
    "                    msg = \"%s, Retrying in %d seconds...\" % (str(ExceptionToCheck), mdelay)\n",
    "                    if logger:\n",
    "                        #logger.exception(msg) # would print stack trace\n",
    "                        logger.warning(msg)\n",
    "                    else:\n",
    "                        print(msg)\n",
    "                    time.sleep(mdelay)\n",
    "                    mtries -= 1\n",
    "                    mdelay *= backoff\n",
    "            return f(*args, **kwargs)\n",
    "\n",
    "        return f_retry  # true decorator\n",
    "\n",
    "    return deco_retry  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "result_dataframe = pd.read_csv(\"./state_data.csv\", index_col=0)\n",
    "result_dataframe['Cities'] = result_dataframe['Cities'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "discover_dataframe = pd.DataFrame({})\n",
    "restaurant_dataframe = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe = result_dataframe.loc[result_dataframe['State']=='Connecticut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>[Ansonia, Berlin, Bloomfield, Branford, Bridge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         State                                             Cities\n",
       "6  Connecticut  [Ansonia, Berlin, Bloomfield, Branford, Bridge..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFC\n",
      "\u001b[32mStar Count: 3.2\n",
      "\u001b[32mReview Count: 612 Google reviews\n",
      "\u001b[32mAttributes: ['$', 'Chicken restaurant']\n",
      "\u001b[32mSummary\n",
      "\u001b[32mAddress\n",
      "\u001b[32mHours\n",
      "\u001b[32mMenu\n",
      "\u001b[32mPhone\n",
      "\u001b[32mWebsite\n",
      "\u001b[32mPicture Link: https://www.google.com/maps/uv?hl=en&pb=!1s0x872b6b664ecd8a0b:0x2ec36344411bae1f!3m1!7e115!4shttps://lh5.googleusercontent.com/p/AF1QipMvTe27iYSPlquyb95T2VUaGDMbbyaf795mpS3R%3Dw520-h350-n-k-no!5sGlendale,+Arizona+Restaurants+-+Google+Search&imagekey=!1e10!2sAF1QipMvTe27iYSPlquyb95T2VUaGDMbbyaf795mpS3R\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for row in result_dataframe.itertuples():\n",
    "  state = row.State\n",
    "  cities = row.Cities\n",
    "    #define query and link\n",
    "  for city in cities:\n",
    "    if len(restaurant_dataframe)%1000==0:\n",
    "      counter+=1\n",
    "    query = f\"{city}, {state} Restaurants\"\n",
    "    query = query.replace(\",\", \"%2C\").replace(\" \", \"+\").replace(\" \", \"%20\")\n",
    "    main_link = f\"https://www.google.com/search?q={query}\"\n",
    "\n",
    "  #MACBOOK DATA\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"no-sandbox\")\n",
    "    options.add_argument(\"disable-dev-shm-usage\")\n",
    "#     options.add_argument(\"headless\")\n",
    "    options.add_argument(f\"user-data-dir=/Users/brianphelps/Library/Application Support/Google/Chrome/Thread_{counter}\")\n",
    "    driver = webdriver.Chrome(executable_path=\"/Users/brianphelps/Desktop/chromedriver\", chrome_options=options)\n",
    "\n",
    "    \n",
    "    @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "    def serve_link(link):\n",
    "      driver.get(link)\n",
    "    serve_link(main_link)\n",
    "\n",
    "    try:\n",
    "      source = driver.page_source\n",
    "      html = BeautifulSoup(source, 'lxml')\n",
    "      # TRY TO FIND MORE RESULTS BUTTON\n",
    "      try:\n",
    "        result = html.find(text='More places').parent.parent.parent['href']\n",
    "      except:\n",
    "        result = html.find(text='More results').parent.parent.parent['href']\n",
    "      link = f\"https://www.google.com/{result}\"\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      print(f\"{city}, {state}\")\n",
    "      #try to find captcha box to see if google is blocking requests\n",
    "      try:\n",
    "        captcha = html.find('div', class_='recaptcha-checkbox-border').div\n",
    "        #manually click captcha box\n",
    "        breakpoint()\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "    # view all restaurants for location\n",
    "    serve_link(link)\n",
    "    source = driver.page_source\n",
    "    html = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "#     time.sleep(1)\n",
    "#     # 15 total cuisines\n",
    "#     driver.execute_script(f\"\"\"\n",
    "#     document.getElementById('filter_2').querySelectorAll('div.w3RMhb')[{i}].click();\n",
    "#     console.log({i})\n",
    "#     \"\"\")\n",
    "\n",
    "    time.sleep(3)\n",
    "    # grab 'discover more places' items\n",
    "    try:\n",
    "      more_places = html.find(text='Discover more places').parent.parent.parent.find('g-scrolling-carousel').div.div.find_next('div').parent\n",
    "      for place in more_places:\n",
    "          link = f\"https://www.google.com{place.a['href']}\"\n",
    "          try:\n",
    "            img = place.a.find('g-inner-card').div.img['src']\n",
    "          except:\n",
    "            img = place.a.find('g-inner-card').div.img['data-img-url']\n",
    "          title = place.a.find('g-inner-card').find_all('div')[1].text.strip()\n",
    "          temp_result = {\n",
    "            'title': title,\n",
    "            'img': img,\n",
    "            'link': link,\n",
    "            'city': [city],\n",
    "            'state': [state]\n",
    "          }\n",
    "          discover_dataframe = discover_dataframe.append(temp_result, ignore_index=True)\n",
    "    except:\n",
    "      pass\n",
    "    \n",
    "    #try to click next button\n",
    "    restaurants_exist = True\n",
    "    while restaurants_exist:\n",
    "      try:\n",
    "        restaurant_html = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        restaurants = restaurant_html.find('div', class_='rl_full-list').div.div.div.div.find_next_siblings()[2].find_next('div').parent\n",
    "        #grab all restaurant info\n",
    "        restaurant_length = len(restaurants)\n",
    "      except:\n",
    "        restaurants_exist = False\n",
    "        break\n",
    "      if restaurants_exist==True:\n",
    "        for idx, restaurant in enumerate(restaurants):\n",
    "          try:\n",
    "            try:\n",
    "              temp_rest = pd.DataFrame()\n",
    "              title = restaurant.a.div.find_next('div').find_next_siblings()[0].div.text\n",
    "              print(title)\n",
    "              # OPEN RESTAURANT DETAILS\n",
    "              driver.execute_script(f\"\"\"\n",
    "              document.querySelector(\"#rl_ist0 > div > div > div:nth-child({idx+1}) > div > div.uMdZh.rl-qs-crs-t.mnr-c > div > a > div\").click()\n",
    "              \"\"\")\n",
    "              time.sleep(3)\n",
    "              restaurant_html = BeautifulSoup(driver.page_source, 'lxml')\n",
    "              container = restaurant_html.find_all('span', text=title)[0].parent.parent.parent.parent.parent\n",
    "            except:\n",
    "              container = np.nan\n",
    "              pass\n",
    "  #             breakpoint()\n",
    "          #     print(container)\n",
    "\n",
    "            try:\n",
    "              star_count = container.find('g-review-stars').parent.span.text\n",
    "              print(Fore.GREEN + f\"Star Count: {star_count}\")\n",
    "            except:\n",
    "              star_count = np.nan\n",
    "              print(Fore.GREEN + f\"Star Count Error\")\n",
    "\n",
    "            try:\n",
    "              review_count = container.find('g-review-stars').parent.find_all('span')[3].span.a.text\n",
    "              print(Fore.GREEN + f\"Review Count: {review_count}\")\n",
    "            except:\n",
    "              review_count = np.nan\n",
    "              print(Fore.GREEN + f\"Review Count Error\")\n",
    "\n",
    "            try:\n",
    "              attrs = []\n",
    "              attributes = container.find_all('div', class_='TLYLSe')[1].div.find_all('span')\n",
    "              for attr in attributes:\n",
    "                attrs.append(attr.text.strip())\n",
    "              print(Fore.GREEN + f\"Attributes: {attrs}\")\n",
    "              attributes = attrs\n",
    "            except Exception as e:\n",
    "              attributes = np.nan\n",
    "              print(e)\n",
    "              print(Fore.RED + f\"Attributes Error\")\n",
    "\n",
    "            try:\n",
    "              summary = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/local:editorial summary\"}).div.span.text.strip()\n",
    "              print(Fore.GREEN + \"Summary\")\n",
    "            except:\n",
    "              summary = np.nan\n",
    "              print(Fore.RED + \"Summary\")\n",
    "            try:\n",
    "              address = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/location/location:address\"}).div.div.find_all('span')[1].text\n",
    "              print(Fore.GREEN + \"Address\")\n",
    "            except:\n",
    "              address = np.nan\n",
    "              print(Fore.GREEN + \"Address\")\n",
    "\n",
    "            try:\n",
    "              hours = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/location/location:hours\"}).find_next('table').find_all('tr')\n",
    "              hours_dict ={}\n",
    "              for val in hours:\n",
    "                hours_dict[val.find_all('td')[0].text.strip()]=val.find_all('td')[1].text.strip()\n",
    "              hours = hours_dict\n",
    "              print(Fore.GREEN + \"Hours\")\n",
    "            except:\n",
    "              hours = np.nan\n",
    "              print(Fore.RED + \"Hours Error\")\n",
    "\n",
    "            try:\n",
    "              menu = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/local:menu\"}).find_next('a')['href']\n",
    "              print(Fore.GREEN + \"Menu\")\n",
    "            except:\n",
    "              menu = np.nan\n",
    "              print(Fore.RED + \"Menu\")\n",
    "\n",
    "            try:\n",
    "              phone = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/collection/knowledge_panels/has_phone:phone\"}).div.div.find_all('span')[1].span.text.strip()\n",
    "              print(Fore.GREEN + \"Phone\")\n",
    "            except:\n",
    "              phone = np.nan\n",
    "              print(Fore.RED + \"Phone\")\n",
    "\n",
    "            try:\n",
    "              website = container.find('a', text='Website')['href']\n",
    "              print(Fore.GREEN + \"Website\")\n",
    "            except:\n",
    "              website = np.nan\n",
    "              print(Fore.RED + \"Website\")\n",
    "            #try to find pictures\n",
    "\n",
    "            try:\n",
    "              # define pictures link\n",
    "              pic_link = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/location/location:media\"}).div.a['href']\n",
    "              pic_link = f\"https://www.google.com{pic_link}\"\n",
    "              print(Fore.GREEN + f\"Picture Link: {pic_link}\")\n",
    "\n",
    "              # grab pictures\n",
    "#               serve_link(pic_link)\n",
    "              # grab pictures that owner uploaded\n",
    "              pic_options = webdriver.ChromeOptions()\n",
    "              pic_options.add_argument(\"no-sandbox\")\n",
    "              pic_options.add_argument(\"disable-dev-shm-usage\")\n",
    "#               pic_options.add_argument(\"headless\")\n",
    "              pic_options.add_argument(f\"user-data-dir=/Users/brianphelps/Library/Application Support/Google/Chrome/Picture_{counter}\")\n",
    "              pic_driver = webdriver.Chrome(executable_path=\"/Users/brianphelps/Desktop/chromedriver\", chrome_options=pic_options)\n",
    "              \n",
    "              \n",
    "              \n",
    "              @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "              def serve_pics(link):\n",
    "                pic_driver.get(link)\n",
    "              serve_pics(pic_link)\n",
    "              time.sleep(5)\n",
    "              pic_driver.execute_script(\"\"\"\n",
    "              var divTags = document.getElementsByTagName(\"div\");\n",
    "              var searchText = \"By owner\";\n",
    "              var found;\n",
    "\n",
    "              for (var i = 0; i < divTags.length; i++) {\n",
    "                if (divTags[i].textContent == searchText) {\n",
    "                  found = divTags[i];\n",
    "                  found.click();\n",
    "                  break;\n",
    "                }\n",
    "              }\n",
    "              \"\"\")\n",
    "              for y in range(5):\n",
    "                pic_driver.execute_script(\"\"\"\n",
    "                var objDiv = document.querySelector(\"#gallery > div.widget-pane.widget-pane-visible > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show\");\n",
    "                var height = objDiv.scrollHeight;\n",
    "                objDiv.scrollTop = objDiv.scrollHeight;\n",
    "                \"\"\")\n",
    "                time.sleep(3)\n",
    "              # parse picture html\n",
    "              pics_source = pic_driver.page_source\n",
    "              pics_html = BeautifulSoup(pics_source, 'lxml')\n",
    "\n",
    "              pictures = pics_html.find('div', class_='section-layout section-scrollbox scrollable-y scrollable-show').div\n",
    "              pic_links = []\n",
    "              for pic in pictures:\n",
    "                try:\n",
    "                  pic_link = pic.div.a.div.div['style']\n",
    "                  pic_link = pic_link.split(\"background-image: url\")[1].replace(\"(\", \"\").replace(\")\", \"\").replace(\";\", \"\").replace('\"', '')\n",
    "                  pic_links.append(pic_link)\n",
    "                except:\n",
    "                  pass\n",
    "              pictures = pic_links\n",
    "              print(Fore.GREEN + \"Pictures\")\n",
    "            except Exception as e:\n",
    "              print(\"Picture Error\")\n",
    "              print(e)\n",
    "              pictures = np.nan\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            temp_rest = pd.DataFrame({\n",
    "              'title': [title],\n",
    "              'star_count': [star_count],\n",
    "              'review_count': [review_count],\n",
    "              'attributes': [attributes],\n",
    "              'summary': [summary],\n",
    "              'address': [address],\n",
    "              'hours': [hours],\n",
    "              'menu': [menu],\n",
    "              'phone': [phone],\n",
    "              'website':[website],\n",
    "              'pictures': [pictures],\n",
    "              'city': [city],\n",
    "              'state': [state]\n",
    "            })\n",
    "\n",
    "            restaurant_dataframe = restaurant_dataframe.append(temp_rest, ignore_index=True)\n",
    "            pic_driver.quit()\n",
    "          except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        try:\n",
    "          next_button = restaurant_html.find('a', attrs={\"id\":\"pnnext\"})['href']\n",
    "          next_link = f\"https://www.google.com{next_button}\"\n",
    "          serve_link(next_link)\n",
    "        except:\n",
    "  #         breakpoint()\n",
    "          restaurants_exist = False\n",
    "    discover_dataframe.to_csv(\"./discover.csv\")\n",
    "    restaurant_dataframe.to_csv(\"./restaurants.csv\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MANUALLY CLEAN USER DATA DIRECTORIES\n",
    "# restaurant_dataframe = pd.read_csv(\"./restaurants.csv\")\n",
    "# city_index = list(result_dataframe.loc[(result_dataframe['State']==state), 'Cities'].values)[0].index(city)\n",
    "# remaining_cities = list(result_dataframe.loc[(result_dataframe['State']==state), 'Cities'].values)[0][city_index:]\n",
    "\n",
    "# main_counter = 0\n",
    "# for city in remaining_cities:\n",
    "#     if len(restaurant_dataframe)%1000==0:\n",
    "#       main_counter+=1\n",
    "#     query = f\"{city}, {state} Restaurants\"\n",
    "#     query = query.replace(\",\", \"%2C\").replace(\" \", \"+\").replace(\" \", \"%20\")\n",
    "#     main_link = f\"https://www.google.com/search?q={query}\"\n",
    "\n",
    "#     options = webdriver.ChromeOptions()\n",
    "#     options.add_argument(\"no-sandbox\")\n",
    "#     options.add_argument(\"disable-dev-shm-usage\")\n",
    "#     options.add_argument(\"headless\")\n",
    "#     options.add_argument(f\"user-data-dir=C:/Users/Brian/AppData/Local/Google/Chrome/User Data/Thread_{main_counter}\")\n",
    "#     driver = webdriver.Chrome(executable_path=\"/Users/brianphelps/Desktop/chromedriver\", chrome_options=options)\n",
    "\n",
    "\n",
    "\n",
    "#     @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "#     def serve_link(link):\n",
    "#       driver.get(link)\n",
    "#     serve_link(main_link)\n",
    "\n",
    "#     try:\n",
    "#       source = driver.page_source\n",
    "#       html = BeautifulSoup(source, 'lxml')\n",
    "#       result = html.find(text='More places').parent.parent.parent['href']\n",
    "#       link = f\"https://www.google.com/{result}\"\n",
    "#     except Exception as e:\n",
    "#       print(e)\n",
    "#       print(f\"{city}, {state}\")\n",
    "#       #try to find captcha box to see if google is blocking requests\n",
    "#       try:\n",
    "#         captcha = html.find('div', class_='recaptcha-checkbox-border')\n",
    "#         #manually click captcha box\n",
    "#         breakpoint()\n",
    "#       except:\n",
    "#         pass\n",
    "\n",
    "#     # view all restaurants for location\n",
    "#     serve_link(link)\n",
    "#     source = driver.page_source\n",
    "#     html = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "# #     time.sleep(1)\n",
    "# #     # 15 total cuisines\n",
    "# #     driver.execute_script(f\"\"\"\n",
    "# #     document.getElementById('filter_2').querySelectorAll('div.w3RMhb')[{i}].click();\n",
    "# #     console.log({i})\n",
    "# #     \"\"\")\n",
    "\n",
    "#     time.sleep(3)\n",
    "#     # grab 'discover more places' items\n",
    "#     try:\n",
    "#       more_places = html.find(text='Discover more places').parent.parent.parent.find('g-scrolling-carousel').div.div.find_next('div').parent\n",
    "#       for place in more_places:\n",
    "#           link = f\"https://www.google.com{place.a['href']}\"\n",
    "#           try:\n",
    "#             img = place.a.find('g-inner-card').div.img['src']\n",
    "#           except:\n",
    "#             img = place.a.find('g-inner-card').div.img['data-img-url']\n",
    "#           title = place.a.find('g-inner-card').find_all('div')[1].text.strip()\n",
    "#           temp_dict = {\n",
    "#             'title': title,\n",
    "#             'img': img,\n",
    "#             'link': link\n",
    "#           }\n",
    "#           temp_result = pd.DataFrame({\n",
    "#             'city, state': [f\"{city}, {state}\"],\n",
    "#             'restaurants': [temp_dict]\n",
    "#           })\n",
    "#           discover_dataframe = discover_dataframe.append(temp_result, ignore_index=True)\n",
    "#     except:\n",
    "#       pass\n",
    "\n",
    "#     #try to click next button\n",
    "#     restaurants_exist = True\n",
    "#     while restaurants_exist:\n",
    "#       try:\n",
    "#         restaurant_html = BeautifulSoup(driver.page_source, 'lxml')\n",
    "#         restaurants = restaurant_html.find('div', class_='rl_full-list').div.div.div.div.find_next_siblings()[2].find_next('div').parent\n",
    "#         #grab all restaurant info\n",
    "#         restaurant_length = len(restaurants)\n",
    "#       except:\n",
    "#         restaurants_exist = False\n",
    "#         break\n",
    "#       if restaurants_exist==True:\n",
    "#         for idx, restaurant in enumerate(restaurants):\n",
    "#           try:\n",
    "#             try:\n",
    "#               temp_rest = pd.DataFrame()\n",
    "#               title = restaurant.a.div.find_next('div').find_next_siblings()[0].div.text\n",
    "#               print(title)\n",
    "#               # OPEN RESTAURANT DETAILS\n",
    "#               driver.execute_script(f\"\"\"\n",
    "#               document.querySelector(\"#rl_ist0 > div > div > div:nth-child({idx+1}) > div > div.uMdZh.rl-qs-crs-t.mnr-c > div > a > div\").click()\n",
    "#               \"\"\")\n",
    "#               time.sleep(3)\n",
    "#               restaurant_html = BeautifulSoup(driver.page_source, 'lxml')\n",
    "#               container = restaurant_html.find_all('span', text=title)[0].parent.parent.parent.parent.parent\n",
    "#             except:\n",
    "#               container = np.nan\n",
    "#               pass\n",
    "#   #             breakpoint()\n",
    "#           #     print(container)\n",
    "\n",
    "#             try:\n",
    "#               star_count = container.find('g-review-stars').parent.span.text\n",
    "#               print(Fore.GREEN + f\"Star Count: {star_count}\")\n",
    "#             except:\n",
    "#               star_count = np.nan\n",
    "#               print(Fore.GREEN + f\"Star Count Error\")\n",
    "\n",
    "#             try:\n",
    "#               review_count = container.find('g-review-stars').parent.find_all('span')[3].span.a.text\n",
    "#               print(Fore.GREEN + f\"Review Count: {review_count}\")\n",
    "#             except:\n",
    "#               review_count = np.nan\n",
    "#               print(Fore.GREEN + f\"Review Count Error\")\n",
    "\n",
    "#             try:\n",
    "#               attrs = []\n",
    "#               attributes = container.find_all('div', class_='TLYLSe')[1].div.find_all('span')\n",
    "#               for attr in attributes:\n",
    "#                 attrs.append(attr.text.strip())\n",
    "#               print(Fore.GREEN + f\"Attributes: {attrs}\")\n",
    "#               attributes = attrs\n",
    "#             except Exception as e:\n",
    "#               attributes = np.nan\n",
    "#               print(e)\n",
    "#               print(Fore.RED + f\"Attributes Error\")\n",
    "\n",
    "#             try:\n",
    "#               summary = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/local:editorial summary\"}).div.span.text.strip()\n",
    "#               print(Fore.GREEN + \"Summary\")\n",
    "#             except:\n",
    "#               summary = np.nan\n",
    "#               print(Fore.RED + \"Summary\")\n",
    "#             try:\n",
    "#               address = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/location/location:address\"}).div.div.find_all('span')[1].text\n",
    "#               print(Fore.GREEN + \"Address\")\n",
    "#             except:\n",
    "#               address = np.nan\n",
    "#               print(Fore.GREEN + \"Address\")\n",
    "\n",
    "#             try:\n",
    "#               hours = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/location/location:hours\"}).find_next('table').find_all('tr')\n",
    "#               hours_dict ={}\n",
    "#               for val in hours:\n",
    "#                 hours_dict[val.find_all('td')[0].text.strip()]=val.find_all('td')[1].text.strip()\n",
    "#               hours = hours_dict\n",
    "#               print(Fore.GREEN + \"Hours\")\n",
    "#             except:\n",
    "#               hours = np.nan\n",
    "#               print(Fore.RED + \"Hours Error\")\n",
    "\n",
    "#             try:\n",
    "#               menu = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/local:menu\"}).find_next('a')['href']\n",
    "#               print(Fore.GREEN + \"Menu\")\n",
    "#             except:\n",
    "#               menu = np.nan\n",
    "#               print(Fore.RED + \"Menu\")\n",
    "\n",
    "#             try:\n",
    "#               phone = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/collection/knowledge_panels/has_phone:phone\"}).div.div.find_all('span')[1].span.text.strip()\n",
    "#               print(Fore.GREEN + \"Phone\")\n",
    "#             except:\n",
    "#               phone = np.nan\n",
    "#               print(Fore.RED + \"Phone\")\n",
    "\n",
    "#             try:\n",
    "#               website = container.find('a', text='Website')['href']\n",
    "#               print(Fore.GREEN + \"Website\")\n",
    "#             except:\n",
    "#               website = np.nan\n",
    "#               print(Fore.RED + \"Website\")\n",
    "#             #try to find pictures\n",
    "\n",
    "#             try:\n",
    "#               # define pictures link\n",
    "#               pic_link = restaurant_html.find('div', attrs={\"data-attrid\":\"kc:/location/location:media\"}).div.a['href']\n",
    "#               pic_link = f\"https://www.google.com{pic_link}\"\n",
    "#               print(Fore.GREEN + f\"Picture Link: {pic_link}\")\n",
    "\n",
    "#               # grab pictures that owner uploaded\n",
    "#               pic_options = webdriver.ChromeOptions()\n",
    "#               pic_options.add_argument(\"no-sandbox\")\n",
    "#               pic_options.add_argument(\"disable-dev-shm-usage\")\n",
    "#               pic_options.add_argument(\"headless\")\n",
    "#               pic_options.add_argument(f\"user-data-dir=C:/Users/Brian/AppData/Local/Google/Chrome/User Data/Picture_{main_counter}\")\n",
    "#               pic_driver = webdriver.Chrome(executable_path=\"/Users/brianphelps/Desktop/chromedriver\", chrome_options=pic_options)\n",
    "\n",
    "#               @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "#               def serve_pics(link):\n",
    "#                 pic_driver.get(link)\n",
    "#               serve_pics(pic_link)\n",
    "#               time.sleep(5)\n",
    "#               pic_driver.execute_script(\"\"\"\n",
    "#               var divTags = document.getElementsByTagName(\"div\");\n",
    "#               var searchText = \"By owner\";\n",
    "#               var found;\n",
    "\n",
    "#               for (var i = 0; i < divTags.length; i++) {\n",
    "#                 if (divTags[i].textContent == searchText) {\n",
    "#                   found = divTags[i];\n",
    "#                   found.click();\n",
    "#                   break;\n",
    "#                 }\n",
    "#               }\n",
    "#               \"\"\")\n",
    "#               for y in range(5):\n",
    "#                 pic_driver.execute_script(\"\"\"\n",
    "#                 var objDiv = document.querySelector(\"#gallery > div.widget-pane.widget-pane-visible > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show\");\n",
    "#                 var height = objDiv.scrollHeight;\n",
    "#                 objDiv.scrollTop = objDiv.scrollHeight;\n",
    "#                 \"\"\")\n",
    "#                 time.sleep(3)\n",
    "#               # parse picture html\n",
    "#               pics_source = pic_driver.page_source\n",
    "#               pics_html = BeautifulSoup(pics_source, 'lxml')\n",
    "\n",
    "#               pictures = pics_html.find('div', class_='section-layout section-scrollbox scrollable-y scrollable-show').div\n",
    "#               pic_links = []\n",
    "#               for pic in pictures:\n",
    "#                 try:\n",
    "#                   pic_link = pic.div.a.div.div['style']\n",
    "#                   pic_link = pic_link.split(\"background-image: url\")[1].replace(\"(\", \"\").replace(\")\", \"\").replace(\";\", \"\").replace('\"', '')\n",
    "#                   pic_links.append(pic_link)\n",
    "#                 except:\n",
    "#                   pass\n",
    "#               pictures = pic_links\n",
    "#               print(Fore.GREEN + \"Pictures\")\n",
    "#             except Exception as e:\n",
    "#               print(\"Picture Error\")\n",
    "#               print(e)\n",
    "#               pictures = np.nan\n",
    "\n",
    "#             clear_output(wait=True)\n",
    "#             temp_rest = pd.DataFrame({\n",
    "#               'title': [title],\n",
    "#               'star_count': [star_count],\n",
    "#               'review_count': [review_count],\n",
    "#               'attributes': [attributes],\n",
    "#               'summary': [summary],\n",
    "#               'address': [address],\n",
    "#               'hours': [hours],\n",
    "#               'menu': [menu],\n",
    "#               'phone': [phone],\n",
    "#               'website':[website],\n",
    "#               'pictures': [pictures]\n",
    "#             })\n",
    "\n",
    "#             restaurant_dataframe = restaurant_dataframe.append(temp_rest, ignore_index=True)\n",
    "#             pic_driver.quit()\n",
    "#           except Exception as e:\n",
    "#             print(e)\n",
    "#             continue\n",
    "#         try:\n",
    "#           next_button = restaurant_html.find('a', attrs={\"id\":\"pnnext\"})['href']\n",
    "#           next_link = f\"https://www.google.com{next_button}\"\n",
    "#           serve_link(next_link)\n",
    "#         except:\n",
    "#   #         breakpoint()\n",
    "#           restaurants_exist = False\n",
    "#     restaurant_dataframe.to_csv(\"./restaurants.csv\")\n",
    "#     driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
